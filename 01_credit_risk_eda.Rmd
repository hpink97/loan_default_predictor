---
title: "01_credit_risk_eda"
author: "HJ Pink"
date: "2023-05-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Credit Risk Exploratory Data Analysis

https://www.kaggle.com/competitions/home-credit-default-risk/data

### Load libraries

```{r message=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
library(ggcorrplot)
library(ggridges)


source('helper_functions.R')
```



## Import Data

### Application data
Import `application_train.csv`, this is the main table which contains data regarding the credit application. 

```{r}
applications <- clean_read_csv('data/application_train.csv')%>%
    mutate(
        credit_income_ratio = amt_credit / amt_income_total,
        annuity_income_ratio = amt_annuity / amt_income_total,
        income_per_family_member = amt_income_total / cnt_fam_members, 
        perc_adult_life_employed = abs(days_employed)/(abs(days_birth) - (18*365)),
        organization_type = organization_type %>% 
          gsub('Type \\d{1,2}|: type \\d{1,2}','',.) %>% 
          trimws() %>% factor(),
        is_childless = ifelse(cnt_children==0,1,0) %>% factor()
    )


head(applications)
```

```{r}
previous_credits <- clean_read_csv('data/bureau.csv')%>%
  ##replace NA values with zeros - as screws with ratios
  replace_na(list(amt_credit_sum = 0, amt_credit_sum_debt = 0,
                  amt_credit_sum_overdue=0, credit_day_overdue =0, amt_annuity=0))%>%
    mutate(days_since_credit_update = -days_credit_update,
           debt_to_credit_ratio = ifelse(amt_credit_sum == 0, 0,
                                         amt_credit_sum_debt / amt_credit_sum),
           overdue_to_credit_ratio = ifelse(amt_credit_sum == 0, 0, 
                                            amt_credit_sum_overdue / amt_credit_sum))


previous_credits_agg <- previous_credits %>%
    group_by(sk_id_curr) %>%
    summarise(
        total_credit_sum = sum(amt_credit_sum, na.rm = TRUE),
        total_credit_debt = sum(amt_credit_sum_debt, na.rm = TRUE),
        total_credit_overdue = sum(amt_credit_sum_overdue, na.rm = TRUE),
        total_days_overdue = sum(credit_day_overdue, na.rm = TRUE),
        total_annunity = sum(amt_annuity, na.rm = TRUE),
        count_active_credits = sum(credit_active == 'Active'),
        count_closed_credits = sum(credit_active == 'Closed'),
        min_debt_to_credit_ratio = min(debt_to_credit_ratio, na.rm = TRUE),
        max_debt_to_credit_ratio = max(debt_to_credit_ratio, na.rm=TRUE),
        max_overdue_to_credit_ratio = max(overdue_to_credit_ratio, na.rm = TRUE),
        avg_days_since_credit_update = mean(days_since_credit_update, na.rm = TRUE)) %>% 
  mutate(
    credit_to_annuity_ratio = ifelse(total_annunity ==0, 0,total_credit_sum/total_annunity),
    debt_to_credit_ratio = ifelse(total_credit_sum ==0, 0,total_credit_debt/total_credit_sum),
    overdue_to_credit_ratio = ifelse(total_credit_sum ==0, 0,total_credit_overdue/total_credit_sum)
    )
##remove large variable to save memory
rm(previous_credits) 

##view aggregated dataset
head(previous_credits_agg)
```


```{r}
credit_card_balances <- clean_read_csv('data/credit_card_balance.csv')%>%
  replace_na(list(amt_drawings_atm_current = 0, amt_drawings_current = 0,
                  amt_drawings_other_current=0, amt_drawings_pos_current =0)) %>% 
  mutate(total_drawings = amt_drawings_atm_current + amt_drawings_current + amt_drawings_other_current + amt_drawings_pos_current,
         dpd_delayed = ifelse(sk_dpd > 0, 1, 0))

credit_data_agg <- credit_card_balances %>%
  group_by(sk_id_curr) %>%
  summarise(
    n_months_balances = n(),
    mean_balance = mean(amt_balance, na.rm = TRUE),
    sd_balance = sd(amt_balance, na.rm = TRUE),
    max_credit_limit = max(amt_credit_limit_actual, na.rm = TRUE),
    total_drawings_sum = sum(total_drawings, na.rm = TRUE),
    max_mth_drawings = max(total_drawings, na.rm = TRUE),
    total_point_of_sale_drawings = sum(amt_drawings_pos_current, na.rm = TRUE),
    total_payments_sum = sum(amt_payment_total_current, na.rm = TRUE),
    total_dpd = max(sk_dpd, na.rm = TRUE),
    count_dpd_delayed = sum(dpd_delayed, na.rm = TRUE)
  )

##balance change analysis 
multiple_balances <- filter(credit_data_agg, n_months_balances >2)$sk_id_curr 

mth_balance_change <- credit_card_balances %>%
  filter(sk_id_curr %in% multiple_balances) %>% 
  arrange(sk_id_curr, months_balance) %>%
  group_by(sk_id_curr) %>%
  mutate(balance_change = amt_balance - lag(amt_balance))

# Calculate the mean monthly balance change
balance_change_agg <- mth_balance_change %>%
  ungroup() %>% 
  group_by(sk_id_curr) %>%
  summarise(min_balance_change = min(balance_change, na.rm = TRUE),
            max_balance_change = max(balance_change, na.rm = TRUE), 
            median_balance_change = median(balance_change, na.rm = TRUE))

rm(credit_card_balances)

credit_agg <- merge(credit_data_agg, balance_change_agg, by = 'sk_id_curr',all.x=TRUE) 

head(credit_agg)
```
```{r}
installments_payments <- clean_read_csv('data/installments_payments.csv') %>% 
  replace_na(list(days_entry_payment =0, amt_payment =0)) %>% 
  mutate(amt_instalment = ifelse(amt_instalment==0, 0.1, amt_instalment),
         days_before_deadline =days_instalment-days_entry_payment,
         is_late = ifelse(days_before_deadline <0, 1, 0), 
         perc_install_paid = amt_payment/amt_instalment, 
         is_underpaid = ifelse(perc_install_paid <1, 1,0 ))
  
installments_agg <- installments_payments %>% 
  group_by(sk_id_curr) %>% 
  summarise(
    n_installments = n(),
    n_late_payments = sum(is_late,na.rm = TRUE),
    n_underpaid = sum(is_underpaid,na.rm = TRUE),
    total_amt_instalment = sum(amt_instalment,na.rm = TRUE),
    total_amt_payment = sum(amt_payment,na.rm = TRUE),
    median_days_before_deadline = median(days_before_deadline, na.rm = TRUE),
    min_days_before_deadline = min(days_before_deadline, na.rm = TRUE),
    min_perc_installment_paid = min(perc_install_paid, na.rm=TRUE)
  ) %>% 
  mutate(perc_late = n_late_payments/n_installments,
         perc_underpaid = n_underpaid/n_installments, 
         overall_perc_paid = total_amt_payment/total_amt_instalment)

head(installments_agg,10)

```

```{r}
previous_applications <- clean_read_csv('data/previous_application.csv') %>% 
  mutate(is_downpayment = ifelse(!is.na(amt_down_payment) & amt_down_payment>0, 
                                 1,0))

##filter based on success of application

accepted_applications <- filter(previous_applications, 
                                name_contract_status %in% c('Approved','Unused offer'))

rejected_applications <- filter(previous_applications, 
                                name_contract_status %in% c('Refused','Canceled'))

##calculate aggreagted statistics
total_applications <- count(previous_applications, 
                            sk_id_curr, 
                            name = 'total_num_previous_apps')
accepted_agg <- accepted_applications %>% 
  group_by(sk_id_curr) %>% 
  summarise(
    total_accepted_apps = n(),
    total_accepted_credit = sum(amt_credit, na.rm = TRUE),
    accepted_mean_downpayment_rate = mean(rate_down_payment, na.rm=TRUE), 
    accepted_prop_w_downpayment = sum(is_downpayment)/n(),
    most_recent_accepted = max(days_decision, na.rm = FALSE), 
    accepted_max_days_last_due = max(days_last_due, na.rm = FALSE),
    accepted_max_days_first_due = max(days_first_due, na.rm = FALSE)
  )

rejected_agg <- rejected_applications %>% 
group_by(sk_id_curr) %>% 
summarise(
  total_rejected_apps = n(),
  total_rejected_credit = sum(amt_credit, na.rm = TRUE),
  rejected_mean_downpayment_rate = mean(rate_down_payment, na.rm=TRUE), 
  rejected_prop_w_downpayment = sum(is_downpayment)/n(),
  most_recent_rejected = max(days_decision, na.rm = FALSE)
)


previous_applications_agg <- merge(total_applications, accepted_agg, 
                                   by='sk_id_curr', all.x=TRUE) %>% 
  merge(rejected_agg,by='sk_id_curr', all.x=TRUE) %>% 
  mutate(across(everything(), ~replace(., is.na(.) | is.nan(.) | is.infinite(.), 0)),
         accepted_rate = total_accepted_apps/total_num_previous_apps,
         prop_credit_rejected = total_rejected_credit/(total_rejected_credit+total_accepted_credit))
 
# Print the aggregated statistics
head(previous_applications_agg)

  
```

```{r}
df <- merge(applications, previous_credits_agg, by = 'sk_id_curr', all.x=TRUE) %>% 
  merge(credit_agg, by = 'sk_id_curr', all.x=TRUE) %>% 
  merge(installments_agg, by = 'sk_id_curr', all.x=TRUE) %>% 
  merge(previous_applications_agg, by = 'sk_id_curr', all.x=TRUE)
  

##replace NAs in aggregated columns with zeros. In these datsets NA means no data
cols2replace <- c(colnames(credit_agg), colnames(installments_agg),
                  colnames(previous_credits_agg), colnames(previous_applications_agg)) %>% unique()
df[,cols2replace] <- lapply(df[,cols2replace] , function(x) ifelse(is.na(x), 0, x))

info <- get_dataset_overview(df) 


write_rds(df, 'data/all_data_merged.rds.gz',compress = 'gz')


```



```{r fig.width=20}
# Get the numeric column names from the dataset
numeric_columns <- filter(info, Data_Type =='numeric')$Column

numeric_data <- select(df, all_of(c('target',numeric_columns))) %>% mutate(target = as.numeric(target))

##calculate correlation matrix
corr_matrix <- cor(numeric_data, use = "pairwise.complete.obs")
ggcorrplot(corr_matrix,
           type = "lower",
           hc.order = TRUE,
           outline.col = "white",
           lab_size = 0.5)+
  theme(legend.position = 'bottom')
```


## do feature selection before imputation.
```{r}
# Create an empty dataframe to store the results
binomial_glm_df <- data.frame(feature = character(),
                         coefficient = numeric(),
                         p_value = numeric(),
                         stringsAsFactors = FALSE)


# Iterate over each numeric column and fit the binomial GLM
for (col in c(numeric_columns)) {
  # Construct the formula with the current column
  formula <- as.formula(paste("target ~", col))
  
  # Fit the binomial GLM
  model <- glm(formula, 
               data = df[!is.na(df[,col]),c('target',col)], 
               family = binomial(link="logit"))
  
  # Get the coefficient and p-value
  coef <- coef(model)[2]  # Assuming the column is the second coefficient in the model
  p_value <- summary(model)$coefficients[2, 4]  # Assuming the column is the second coefficient in the model summary
  
  # Append the results to the dataframe
  binomial_glm_df <- rbind(binomial_glm_df, 
                            data.frame(feature = col, coefficient = coef,
                                       p_value = p_value, AIC = model$aic,
                                       deviance_reduction = 1-(model$deviance/model$null.deviance )))
}

#use bonferroni-hocherg to adjust p-values
binomial_glm_df <- binomial_glm_df %>% 
  mutate(abs_coef = abs(coefficient), 
         p_adjust = p.adjust(p_value, method = 'bonferroni'),
         minus_log10_padj = -log10(p_adjust+1e-200)) %>% 
  arrange(-deviance_reduction)
```


### Plot Model 
```{r}
ggplot(binomial_glm_df,aes(x=minus_log10_padj,
                           y=deviance_reduction*100))+
  geom_jitter(alpha=0.4)+
  scale_y_continuous(breaks = seq(0, 10, 0.5))+
  labs(x='-log10(p-adjust)', y ='Model deviance reduction %')+
  #geom_hline(yintercept = 15)+geom_vline(xintercept = 0.8)
  theme(panel.grid.minor = element_blank())
```
### Perform feature selection on numeric columns

Keep only numeric columns that reduced the residual deviance of the fitted model (compared to null deviance) by at least 0.15%

```{r}
numeric_columns_to_keep <- filter(binomial_glm_df, deviance_reduction >0.0015)$feature

print(paste('Keeping', length(numeric_columns_to_keep), 
            'numeric features out of the original',
            length(numeric_columns)))
```

```{r warning=FALSE}
for(x in numeric_columns_to_keep[1:20]){
  plot_numeric_variable(feature = x, df=df)
}

```



## Use Chi-squared to identify the most relavent categorical values

```{r}


# Create an empty vector to store p-values
p_values <- c()
chi_sq_statistic <- c()
min_max_diff <- c()

# Loop over each categorical feature
categ_features <- filter(info, Data_Type =='factor')$Column
categ_features <- categ_features[categ_features!='target']

for(feature in categ_features){
  ##create a sliced df for feature of intertest
  feature_df <- df[,c('target', feature)]
  colnames(feature_df)[colnames(feature_df)==feature] <- 'feature_x'
  
  # Create a contingency table 
    contingency_table <- table(feature_df$feature_x, feature_df$target)

  # Perform the chi-squared test
  chi_squared_test <- chisq.test(contingency_table)
  
  ##calculate the difference in proportion of defaults between highest and lowest groups
    category_proportions <- feature_df %>% 
    group_by(feature_x) %>% 
    summarise(prop_defult = target %>% as.character %>% as.numeric %>% mean, 
              count = n()) %>% 
    filter(count>500) #require a group to have over 500 datapoints to be counted
  
  diff <- max(category_proportions$prop_defult)-min(category_proportions$prop_defult)

  # Store the p-value
  p_values <- c(p_values, chi_squared_test$p.value)
  chi_sq_statistic <- c(chi_sq_statistic, chi_squared_test$statistic)
  min_max_diff <- c(min_max_diff, diff)

}

# Create a data frame of features and their corresponding p-values
chi_sq_df <- data.frame(feature = categ_features,
                        p_adjust = p.adjust(p_values, method='BH'),
                        chi_sq_statistic = chi_sq_statistic,
                        min_max_diff = min_max_diff) %>% 
  arrange(p_adjust)

# Print the feature importances
chi_sq_df

```

```{r}
chi_sq_df <- chi_sq_df %>% 
  mutate(minus_log10_padj =-log10(p_adjust+1e-200), 
         remove_feature = ifelse(min_max_diff<0.03 & p_adjust >1e-10,TRUE,FALSE)) 

ggplot(chi_sq_df, aes(x=min_max_diff, y=minus_log10_padj, col=remove_feature ))+
  geom_point()+
  labs(x='Maxium category difference in Loan Default Proportion', 
       y = 'Chi-squared -log10(p-adjust)')
```


```{r fig.width=12, fig.height=6}
categ_cols_to_keep <- chi_sq_df$feature[!chi_sq_df$remove_feature]

for(x in categ_cols_to_keep){
  plot_categorical_variable(x)
}
```

```{r}
final_data <- df[,c('target','sk_id_curr', numeric_columns_to_keep, categ_cols_to_keep)]
get_dataset_overview(final_data) %>% filter(Perc_missing >0)
write_rds(final_data, 'data/clean_feature_selected_data.rds.gz',compress = 'gz')
```

