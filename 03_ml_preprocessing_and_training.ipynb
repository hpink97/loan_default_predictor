{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hpink97/loan_default_predictor/blob/main/03_ml_preprocessing_and_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load modules"
      ],
      "metadata": {
        "id": "uaRJh51_49sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install bayesian-optimization\n",
        "#!pip install miceforest --no-cache-dir"
      ],
      "metadata": {
        "id": "3rWjb4lu8lqP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4zBpXMg7jyhX"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import gc #free up memory\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import miceforest as mf ##forest based imputation\n",
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, balanced_accuracy_score,precision_recall_curve,roc_curve, auc\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler,StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Dataset` class for ML preprocessing\n",
        "\n",
        "The `Dataset` class is designed to handle the preprocessing and splitting of a dataset for machine learning tasks. Here is a summary of its functionality:\n",
        "\n",
        "1. Initialization: The class takes in a pandas DataFrame (`df`) representing the dataset and the target variable (`target`). It also accepts additional parameters like `is_test` to indicate if the dataset is a test set, `scaler` for scaling numeric columns, and `trained_cols` for indicating specific columns to be used in the final dataset.\n",
        "\n",
        "2. Preprocessing: The `preprocess()` method performs preprocessing tasks on the dataset. It includes basic imputations for missing values, smart imputations using the `miceforest` package for remaining missing values, scaling of numeric columns, and label encoding for binary columns. It also performs one-hot encoding for categorical columns.\n",
        "\n",
        "3. Splitting Data: The `split_data()` method splits the preprocessed dataset into training, evaluation, and testing sets. It takes parameters like `test_size` and `eval_size` to control the size of the test and evaluation sets, respectively. It prints information about the sizes and positive rates of each split.\n"
      ],
      "metadata": {
        "id": "20oBBUx8NDiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "    def __init__(self, df, target,is_test=False, scaler=None, trained_cols = None):\n",
        "        self.df = df\n",
        "        self.is_test = is_test\n",
        "        self.target = target\n",
        "        self.X = self.df.drop(columns=[self.target])\n",
        "        self.X_train = None\n",
        "        self.X_test = None\n",
        "        self.X_eval = None\n",
        "        self.y_eval = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        self.preprocessed = False\n",
        "        self.scaler = scaler\n",
        "        self.label_encoders = None\n",
        "        self.final_X_cols = None\n",
        "        if self.is_test:\n",
        "          self.y = None\n",
        "        else:\n",
        "          self.y = self.df[self.target]\n",
        "\n",
        "    ##method to pre-process the df\n",
        "    def preprocess(self, impute_dict=None, imputation_kernel_iterations = 4, imputation_kernel_ntrees = 50):\n",
        "       # Basic imputations\n",
        "      if impute_dict is not None:\n",
        "        print(f'Performing basic imputations based on {len(impute_dict)} features supplied impute_dict')\n",
        "        for col, strategy in impute_dict.items():\n",
        "          if col not in self.X.columns:\n",
        "            print(f\"Skipping imputation for column '{col}' as it does not exist in the dataset.\")\n",
        "            continue\n",
        "          if strategy == 'mean':\n",
        "              self.X[col].fillna(self.X[col].mean(), inplace=True)\n",
        "          elif strategy == 'median':\n",
        "              self.X[col].fillna(self.X[col].median(), inplace=True)\n",
        "          elif isinstance(strategy, str) and strategy.startswith('percentile_'):\n",
        "              percentile = float(strategy.split('_')[1])\n",
        "              self.X[col].fillna(self.X[col].quantile(percentile / 100), inplace=True)\n",
        "          elif isinstance(strategy, (int, float)):\n",
        "              self.X[col].fillna(strategy, inplace=True)\n",
        "          else:\n",
        "              raise ValueError(f\"Invalid imputation strategy for column '{col}'.\")\n",
        "    #find numeric columns\n",
        "      numeric_cols = self.X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "      ## smart impuations - decision tree based method\n",
        "      count_NA = self.X.isna().sum()\n",
        "      remaining_NA_cols = count_NA[count_NA>0].shape[0]\n",
        "      if  remaining_NA_cols> 0:\n",
        "        print(f'Performing decision-tree based imputations of {remaining_NA_cols} remaining features with missing data')\n",
        "        kernal = mf.ImputationKernel(\n",
        "            self.X[numeric_cols],\n",
        "            random_state=42\n",
        "            )\n",
        "        # Run the MICE algorithm for 2 iterations\n",
        "        kernal.mice(iterations=imputation_kernel_iterations,\n",
        "                    n_estimators=imputation_kernel_ntrees)\n",
        "        X_numeric_imputed = kernal.complete_data()\n",
        "        self.X[numeric_cols] = X_numeric_imputed\n",
        "      \n",
        "      ##scale numeric cols\n",
        "      print('Scaling numeric data')\n",
        "      if self.scaler is None:\n",
        "        self.scaler = StandardScaler()\n",
        "        self.X[numeric_cols] = self.scaler.fit_transform(self.X[numeric_cols])\n",
        "      else:\n",
        "        self.X[numeric_cols] = self.scaler.transform(self.X[numeric_cols])\n",
        "  \n",
        "      \n",
        "      # Perform label encoding for binary columns\n",
        "      print('One-hot-encoding categorical vars')\n",
        "      binary_cols = [col for col in self.X.columns if self.X[col].nunique() == 2]\n",
        "      self.label_encoders = {}\n",
        "\n",
        "      # Label encode binary columns\n",
        "      for col in binary_cols:\n",
        "          label_encoder = LabelEncoder()\n",
        "          self.X[col] = label_encoder.fit_transform(self.X[col])\n",
        "          # Store the label encoder for later use\n",
        "          self.label_encoders[col] = label_encoder\n",
        "      \n",
        "      # Perform one-hot encoding for categorical columns\n",
        "      categorical_cols = [col for col in self.X.columns if self.X[col].dtype == 'object' and col not in binary_cols]\n",
        "      self.X = pd.get_dummies(self.X, columns=categorical_cols)\n",
        "\n",
        "      if self.final_X_cols is not None:\n",
        "        missing_cols = set(self.final_X_cols) - set(self.X.columns)\n",
        "        for col in missing_cols:\n",
        "          self.X[col] = 0\n",
        "        self.X = self.X[self.final_X_cols]\n",
        "\n",
        "      self.preprocessed = True\n",
        "    \n",
        "\n",
        "    def split_data(self, test_size=0.15,eval_size = 0.15, random_state=42):\n",
        "        if not self.preprocessed:\n",
        "          raise RuntimeError(\"Data has not been preprocessed. Please run the preprocess method.\")\n",
        "        \n",
        "        if self.is_test:\n",
        "          raise RuntimeError(\"Cannot run split_data() method on a test set\")\n",
        "\n",
        "        \n",
        "        X_train_eval, self.X_test, y_train_eval, self.y_test = train_test_split(\n",
        "            self.X, self.y, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        eval_split_size = eval_size/(1-test_size)\n",
        "        self.X_train, self.X_eval, self.y_train, self.y_eval = train_test_split(\n",
        "            X_train_eval, y_train_eval, test_size=eval_split_size, random_state=random_state)\n",
        "\n",
        "        print(f\"{self.X_train.shape[0]} training samples, {self.X_eval.shape[0]} evaluation samples and {self.X_test.shape[0]} testing samples\")\n",
        "        print(f\"{self.y_train.sum()} ({self.y_train.mean()*100:.3f}%) positives in training set\")\n",
        "        print(f\"{self.y_eval.sum()} ({self.y_eval.mean()*100:.3f}%) positives in evaluation set\")\n",
        "        print(f\"{self.y_test.sum()} ({self.y_test.mean()*100:.3f})% positives in testing set\")\n"
      ],
      "metadata": {
        "id": "eOPZJPLIoYyT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `Model` Class for training xgboost models\n",
        "\n",
        "The model class provides a streamlined workflow for feature selection, model training, and evaluation of xgboost models.\n",
        "\n",
        "Here is a summary of the key features and methods of the Model class:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Initialisation**: The class is initialized with the necessary input data using the `Dataset` class, including the training and test sets (`X_train`, `X_test`) and their corresponding target variables (`y_train`, `y_test`).\n",
        "2.   **Feature Selection**: The `select_features()` method allows you to perform feature selection using the `sklearn.feature_selection.SelectKBest` algorithm. It selects the top num_features based on mutual information classification scores.\n",
        "3. **Model Training**: The `train_model()` method trains an XGBoost classifier using the specified xgboost_params. It uses the training data and evaluates the model's performance on the evaluation set (`X_eval`, `y_eval`). Early stopping is implemented to prevent overfitting.\n",
        "4. **Model Evaluation**: The `evaluate_model()` method calculates and prints various evaluation metrics, including F1 score, accuracy, precision, recall, specificity, ROC AUC score, and balanced accuracy. It also selects the optimal threshold for determining binary predictions based on the F1 score.\n",
        "5. **Performance Visualisation**: The class provides several plotting methods to visualise model performance, including `plot_roc_auc()` to visualize the ROC curve and calculate the AUC score, `plot_predictions()` to plot the predicted probabilities against the true labels, and `plot_feature_importance()` to display the feature importances using a bar plot."
      ],
      "metadata": {
        "id": "3CwoN_eXKBWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self, dataset_class):\n",
        "        if not isinstance(dataset_class.X_train, pd.DataFrame) or not isinstance(dataset_class.X_test, pd.DataFrame):\n",
        "            raise TypeError(\"X_train and X_test must be pandas DataFrames\")\n",
        "        if not isinstance(dataset_class.y_train, pd.Series) or not isinstance(dataset_class.y_test, pd.Series):\n",
        "            raise TypeError(\"y_train and y_test must be pandas Series\")\n",
        "        self.X_train = dataset_class.X_train\n",
        "        self.X_eval = dataset_class.X_eval\n",
        "        self.X_test = dataset_class.X_test\n",
        "        self.y_train = dataset_class.y_train\n",
        "        self.y_eval = dataset_class.y_eval\n",
        "        self.y_test = dataset_class.y_test\n",
        "        self.y_pred = None\n",
        "        self.xgboost_params = None\n",
        "        self.num_features = None\n",
        "        self.feature_names = dataset_class.X_train.columns\n",
        "        self.selected_features = None\n",
        "        self.model = None\n",
        "    \n",
        "    def select_features(self, num_features):\n",
        "      if not isinstance(num_features, int) :\n",
        "        raise TypeError(\"num_features must be an int\")\n",
        "      #ensure num features is in correct range\n",
        "      num_features = max(min(int(num_features), self.X_train.shape[1]), 2)\n",
        "      ##perform feature selection\n",
        "      selector = SelectKBest(score_func=mutual_info_classif, k=num_features)\n",
        "      selector.fit(self.X_train, self.y_train)\n",
        "      mask = selector.get_support()\n",
        "      ##splice X datasets for the selected features\n",
        "      self.selected_features = self.feature_names[mask]\n",
        "      self.X_train = self.X_train[self.selected_features]\n",
        "      self.X_eval = self.X_eval[self.selected_features]\n",
        "      self.X_test = self.X_test[self.selected_features]\n",
        "    \n",
        "    def train_model(self, xgboost_params):\n",
        "      self.xgboost_params = xgboost_params\n",
        "      dtrain = xgb.DMatrix(self.X_train, label=self.y_train)\n",
        "      deval = xgb.DMatrix(self.X_eval, label = self.y_eval)\n",
        "      self.model = xgb.train(self.xgboost_params,\n",
        "                             dtrain = dtrain, \n",
        "                             evals=[(deval, 'eval')],verbose_eval=False,\n",
        "                             num_boost_round=700,early_stopping_rounds=20 )\n",
        "      print('Model training completed')\n",
        "    \n",
        "    def evaluate_model(self):\n",
        "      if self.y_pred is None:\n",
        "        dtest = xgb.DMatrix(self.X_test, label=self.y_test)\n",
        "        self.y_pred = self.model.predict(dtest)\n",
        "      ##select best threshold for determining \n",
        "      best_threshold = 0\n",
        "      best_f1 = 0\n",
        "      \n",
        "      # Iterate over different threshold values\n",
        "      for threshold in np.arange(0.1, 1.0, 0.05):\n",
        "          y_pred_binary = (self.y_pred >= threshold).astype(int)\n",
        "          f1 = f1_score(self.y_test, y_pred_binary)\n",
        "\n",
        "          if f1 > best_f1:\n",
        "              best_f1 = f1\n",
        "              best_threshold = threshold\n",
        "      \n",
        "      # Convert predicted probabilities to binary predictions based on the best threshold\n",
        "      y_pred_binary = (self.y_pred >= best_threshold).astype(int)\n",
        "      \n",
        "      # Calculate accuracy metrics\n",
        "      accuracy = accuracy_score(self.y_test, y_pred_binary)\n",
        "      precision = precision_score(self.y_test, y_pred_binary)\n",
        "      recall = recall_score(self.y_test, y_pred_binary)\n",
        "      specificity = recall_score(self.y_test, y_pred_binary, pos_label=0)\n",
        "      roc_auc = roc_auc_score(self.y_test, self.y_pred)\n",
        "      balanced_accuracy = balanced_accuracy_score(self.y_test, y_pred_binary)\n",
        "      \n",
        "      # Print the metrics\n",
        "      print(\"Optimal Threshold:\", best_threshold)\n",
        "      print(\"F1 Score:\", best_f1)\n",
        "      print(\"Accuracy:\", accuracy)\n",
        "      print(\"Precision:\", precision)\n",
        "      print(\"Recall (Sensitivity):\", recall)\n",
        "      print(\"Specificity (True Negative Rate):\", specificity)\n",
        "      print(\"ROC AUC Score:\", roc_auc)\n",
        "      print(\"Balanced Accuracy:\", balanced_accuracy)\n",
        "\n",
        "    \n",
        "    def plot_roc_auc(self):\n",
        "      if self.y_pred is None:\n",
        "        dtest = xgb.DMatrix(self.X_test, label=self.y_test)\n",
        "        self.y_pred = self.model.predict(dtest)\n",
        "      \n",
        "      fpr, tpr, _ = roc_curve(self.y_test, self.y_pred)\n",
        "      roc_auc = roc_auc_score(self.y_test, self.y_pred)\n",
        "      plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
        "      plt.plot([0, 1], [0, 1], 'k--')\n",
        "      plt.xlabel('False Positive Rate')\n",
        "      plt.ylabel('True Positive Rate')\n",
        "      plt.title('Receiver Operating Characteristic')\n",
        "      plt.legend(loc=\"lower right\")\n",
        "      plt.show()\n",
        "    def plot_predictions(self):\n",
        "      if self.y_pred is None:\n",
        "        dtest = xgb.DMatrix(self.X_test, label=self.y_test)\n",
        "        self.y_pred = self.model.predict(dtest)\n",
        "            \n",
        "      sns.regplot(x=self.y_pred, y=self.y_test, scatter_kws={'alpha': 0.3})\n",
        "      plt.xlabel('Predicted Probabilities')\n",
        "      plt.ylabel('True Labels')\n",
        "      plt.title('Predicted Probabilities vs. True Labels')\n",
        "      plt.show()\n",
        "    \n",
        "    def plot_feature_importance(self, n_features =None):\n",
        "      \n",
        "\n",
        "      feature_importances = self.model.get_score(importance_type='weight')\n",
        "      if n_features is None:\n",
        "        n_features = len(feature_importances)\n",
        "\n",
        "      sorted_feature_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "      # Extract feature names and importance scores\n",
        "      features = [x[0] for x in sorted_feature_importances]\n",
        "      importances = [x[1] for x in sorted_feature_importances]\n",
        "\n",
        "      # Create a bar plot of sorted feature importances\n",
        "      plt.figure(figsize=(8, 9.5))\n",
        "      plt.barh(features[0:(n_features-1)][::-1], \n",
        "               importances[0:(n_features-1)][::-1])\n",
        "      plt.xlabel('Importance')\n",
        "      plt.ylabel('Features')\n",
        "      plt.title(f'Top {n_features} Features')\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n"
      ],
      "metadata": {
        "id": "1ElsCYmYhEgR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('all_data_merged.csv')\n"
      ],
      "metadata": {
        "id": "it89TWvV99Oj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_results = pd.read_csv('logistic_regression_results.csv')\n",
        "important_features = lr_results.feature[lr_results.deviance_reduction >0.25]\n",
        "less_relavent_features = lr_results.feature[lr_results.deviance_reduction <= 0.25]"
      ],
      "metadata": {
        "id": "LGV0OZKUnCfl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "impute_dict = {feature: 'median' for feature in less_relavent_features}\n",
        "impute_dict['own_car_age'] = 'percentile_95'"
      ],
      "metadata": {
        "id": "kgRbzyAm6vqc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset(df, target = 'target')\n",
        "data.preprocess(impute_dict=impute_dict,\n",
        "                imputation_kernel_iterations=3, imputation_kernel_ntrees=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IebRLqVB8uDl",
        "outputId": "acb4d778-ecf4-4f2c-ff90-3195f39634c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing basic imputations based on 114 features supplied impute_dict\n",
            "Performing decision-tree based imputations of 10 remaining features with missing data\n",
            "Scaling numeric data\n",
            "One-hot-encoding categorical vars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.split_data()\n",
        "data.X_train.head(20)"
      ],
      "metadata": {
        "id": "asnsdVo5L0SS",
        "outputId": "617226a6-427d-4158-cced-2e952b90eeb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215257 training samples, 46127 evaluation samples and 46127 testing samples\n",
            "17250 (8.014%) positives in training set\n",
            "3858 (8.364%) positives in evaluation set\n",
            "3717 (8.058)% positives in testing set\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        sk_id_curr  name_contract_type  flag_own_car  flag_own_realty  \\\n",
              "46832    -1.205696                   0             1                1   \n",
              "201944    0.543919                   0             0                0   \n",
              "131335   -0.251576                   0             1                0   \n",
              "192603    0.439454                   1             1                1   \n",
              "244844    1.023441                   0             1                1   \n",
              "237241    0.939843                   0             0                0   \n",
              "30269    -1.391658                   0             0                1   \n",
              "297908    1.624238                   0             1                0   \n",
              "81607    -0.812788                   0             1                0   \n",
              "56546    -1.096026                   0             0                1   \n",
              "232396    0.885227                   1             0                0   \n",
              "201595    0.539989                   0             0                0   \n",
              "239570    0.965488                   0             0                1   \n",
              "201092    0.534278                   0             0                1   \n",
              "127269   -0.297592                   0             1                1   \n",
              "169794    0.181014                   0             0                0   \n",
              "103995   -0.559291                   0             0                0   \n",
              "133077   -0.231934                   0             0                0   \n",
              "227305    0.827974                   0             1                1   \n",
              "101555   -0.586327                   0             1                1   \n",
              "\n",
              "        cnt_children  amt_income_total  amt_credit  amt_annuity  \\\n",
              "46832      -0.577538         -0.180488   -0.180216    -0.334426   \n",
              "201944      0.807273         -0.360775    0.199940    -0.499605   \n",
              "131335     -0.577538          0.237017   -1.159238    -0.957570   \n",
              "192603     -0.577538         -0.256398   -0.817476    -0.938941   \n",
              "244844      2.192084          0.616567    1.013426     1.480981   \n",
              "237241      0.807273          0.085197   -1.041084    -0.880260   \n",
              "30269      -0.577538         -0.237421   -1.152888    -1.114676   \n",
              "297908     -0.577538          0.047242   -1.064339    -1.118091   \n",
              "81607       2.192084          4.412069    5.208759     3.035582   \n",
              "56546       0.807273         -0.370264   -0.534120    -0.626283   \n",
              "232396      0.807273         -0.389241   -1.041084    -1.249427   \n",
              "201595     -0.577538         -0.199466   -0.817476    -0.964401   \n",
              "239570      0.807273         -0.047646   -0.180216     0.158003   \n",
              "201092      2.192084          0.237017   -0.012185     0.231588   \n",
              "127269      0.807273          0.616567    1.399150     0.979548   \n",
              "169794      0.807273         -0.237421   -0.929280    -0.766312   \n",
              "103995     -0.577538         -0.180488   -0.855489    -0.473213   \n",
              "133077     -0.577538         -0.294354   -0.855489    -0.687138   \n",
              "227305      0.807273         -0.142533   -0.193163    -0.491532   \n",
              "101555      2.192084          0.616567   -0.224926    -0.173595   \n",
              "\n",
              "        amt_goods_price  region_population_relative  ...  \\\n",
              "46832         -0.226468                    0.310593  ...   \n",
              "201944         0.382619                   -0.149452  ...   \n",
              "131335        -1.140099                    0.756322  ...   \n",
              "192603        -0.725919                    1.078997  ...   \n",
              "244844         0.979524                    0.139676  ...   \n",
              "237241        -0.969554                   -0.765810  ...   \n",
              "30269         -1.091372                   -0.192254  ...   \n",
              "297908        -1.091372                   -0.665963  ...   \n",
              "81607          4.634045                    3.733564  ...   \n",
              "56546         -0.725919                   -0.885177  ...   \n",
              "232396        -0.969554                   -1.286876  ...   \n",
              "201595        -0.725919                   -0.665963  ...   \n",
              "239570        -0.226468                    1.832942  ...   \n",
              "201092        -0.177741                    1.832942  ...   \n",
              "127269         0.796798                    1.078997  ...   \n",
              "169794        -0.847737                    1.078997  ...   \n",
              "103995        -0.847737                   -0.307717  ...   \n",
              "133077        -0.847737                   -0.925448  ...   \n",
              "227305        -0.238650                   -0.307717  ...   \n",
              "101555        -0.226468                    0.270539  ...   \n",
              "\n",
              "        wallsmaterial_mode_Stone, brick  wallsmaterial_mode_Wooden  \\\n",
              "46832                                 1                          0   \n",
              "201944                                0                          0   \n",
              "131335                                0                          0   \n",
              "192603                                1                          0   \n",
              "244844                                0                          0   \n",
              "237241                                0                          0   \n",
              "30269                                 0                          0   \n",
              "297908                                0                          0   \n",
              "81607                                 1                          0   \n",
              "56546                                 1                          0   \n",
              "232396                                0                          0   \n",
              "201595                                0                          0   \n",
              "239570                                1                          0   \n",
              "201092                                0                          0   \n",
              "127269                                0                          0   \n",
              "169794                                0                          0   \n",
              "103995                                0                          0   \n",
              "133077                                0                          0   \n",
              "227305                                0                          0   \n",
              "101555                                0                          0   \n",
              "\n",
              "        wallsmaterial_mode_other  emergencystate_mode_No  \\\n",
              "46832                          0                       1   \n",
              "201944                         1                       0   \n",
              "131335                         0                       1   \n",
              "192603                         0                       1   \n",
              "244844                         1                       0   \n",
              "237241                         1                       0   \n",
              "30269                          1                       0   \n",
              "297908                         0                       1   \n",
              "81607                          0                       1   \n",
              "56546                          0                       1   \n",
              "232396                         1                       0   \n",
              "201595                         1                       0   \n",
              "239570                         0                       1   \n",
              "201092                         1                       0   \n",
              "127269                         1                       0   \n",
              "169794                         1                       0   \n",
              "103995                         1                       0   \n",
              "133077                         1                       0   \n",
              "227305                         1                       0   \n",
              "101555                         1                       0   \n",
              "\n",
              "        emergencystate_mode_Yes  emergencystate_mode_other  age_group_30-45  \\\n",
              "46832                         0                          0                0   \n",
              "201944                        0                          1                0   \n",
              "131335                        0                          0                1   \n",
              "192603                        0                          0                1   \n",
              "244844                        0                          1                1   \n",
              "237241                        0                          1                0   \n",
              "30269                         0                          1                0   \n",
              "297908                        0                          0                1   \n",
              "81607                         0                          0                0   \n",
              "56546                         0                          0                0   \n",
              "232396                        0                          1                0   \n",
              "201595                        0                          1                0   \n",
              "239570                        0                          0                1   \n",
              "201092                        0                          1                1   \n",
              "127269                        0                          1                0   \n",
              "169794                        0                          1                1   \n",
              "103995                        0                          1                1   \n",
              "133077                        0                          1                0   \n",
              "227305                        0                          1                1   \n",
              "101555                        0                          1                1   \n",
              "\n",
              "        age_group_45-60  age_group_60+  age_group_under 30  \n",
              "46832                 0              1                   0  \n",
              "201944                0              0                   1  \n",
              "131335                0              0                   0  \n",
              "192603                0              0                   0  \n",
              "244844                0              0                   0  \n",
              "237241                0              0                   1  \n",
              "30269                 0              0                   1  \n",
              "297908                0              0                   0  \n",
              "81607                 1              0                   0  \n",
              "56546                 0              0                   1  \n",
              "232396                0              0                   1  \n",
              "201595                0              0                   1  \n",
              "239570                0              0                   0  \n",
              "201092                0              0                   0  \n",
              "127269                1              0                   0  \n",
              "169794                0              0                   0  \n",
              "103995                0              0                   0  \n",
              "133077                0              0                   1  \n",
              "227305                0              0                   0  \n",
              "101555                0              0                   0  \n",
              "\n",
              "[20 rows x 302 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffff4fd3-9835-449d-ac87-12ceb9109b42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sk_id_curr</th>\n",
              "      <th>name_contract_type</th>\n",
              "      <th>flag_own_car</th>\n",
              "      <th>flag_own_realty</th>\n",
              "      <th>cnt_children</th>\n",
              "      <th>amt_income_total</th>\n",
              "      <th>amt_credit</th>\n",
              "      <th>amt_annuity</th>\n",
              "      <th>amt_goods_price</th>\n",
              "      <th>region_population_relative</th>\n",
              "      <th>...</th>\n",
              "      <th>wallsmaterial_mode_Stone, brick</th>\n",
              "      <th>wallsmaterial_mode_Wooden</th>\n",
              "      <th>wallsmaterial_mode_other</th>\n",
              "      <th>emergencystate_mode_No</th>\n",
              "      <th>emergencystate_mode_Yes</th>\n",
              "      <th>emergencystate_mode_other</th>\n",
              "      <th>age_group_30-45</th>\n",
              "      <th>age_group_45-60</th>\n",
              "      <th>age_group_60+</th>\n",
              "      <th>age_group_under 30</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46832</th>\n",
              "      <td>-1.205696</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.577538</td>\n",
              "      <td>-0.180488</td>\n",
              "      <td>-0.180216</td>\n",
              "      <td>-0.334426</td>\n",
              "      <td>-0.226468</td>\n",
              "      <td>0.310593</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201944</th>\n",
              "      <td>0.543919</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>-0.360775</td>\n",
              "      <td>0.199940</td>\n",
              "      <td>-0.499605</td>\n",
              "      <td>0.382619</td>\n",
              "      <td>-0.149452</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131335</th>\n",
              "      <td>-0.251576</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.577538</td>\n",
              "      <td>0.237017</td>\n",
              "      <td>-1.159238</td>\n",
              "      <td>-0.957570</td>\n",
              "      <td>-1.140099</td>\n",
              "      <td>0.756322</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192603</th>\n",
              "      <td>0.439454</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.577538</td>\n",
              "      <td>-0.256398</td>\n",
              "      <td>-0.817476</td>\n",
              "      <td>-0.938941</td>\n",
              "      <td>-0.725919</td>\n",
              "      <td>1.078997</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244844</th>\n",
              "      <td>1.023441</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.192084</td>\n",
              "      <td>0.616567</td>\n",
              "      <td>1.013426</td>\n",
              "      <td>1.480981</td>\n",
              "      <td>0.979524</td>\n",
              "      <td>0.139676</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237241</th>\n",
              "      <td>0.939843</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>0.085197</td>\n",
              "      <td>-1.041084</td>\n",
              "      <td>-0.880260</td>\n",
              "      <td>-0.969554</td>\n",
              "      <td>-0.765810</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30269</th>\n",
              "      <td>-1.391658</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.577538</td>\n",
              "      <td>-0.237421</td>\n",
              "      <td>-1.152888</td>\n",
              "      <td>-1.114676</td>\n",
              "      <td>-1.091372</td>\n",
              "      <td>-0.192254</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297908</th>\n",
              "      <td>1.624238</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.577538</td>\n",
              "      <td>0.047242</td>\n",
              "      <td>-1.064339</td>\n",
              "      <td>-1.118091</td>\n",
              "      <td>-1.091372</td>\n",
              "      <td>-0.665963</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81607</th>\n",
              "      <td>-0.812788</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.192084</td>\n",
              "      <td>4.412069</td>\n",
              "      <td>5.208759</td>\n",
              "      <td>3.035582</td>\n",
              "      <td>4.634045</td>\n",
              "      <td>3.733564</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56546</th>\n",
              "      <td>-1.096026</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>-0.370264</td>\n",
              "      <td>-0.534120</td>\n",
              "      <td>-0.626283</td>\n",
              "      <td>-0.725919</td>\n",
              "      <td>-0.885177</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232396</th>\n",
              "      <td>0.885227</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>-0.389241</td>\n",
              "      <td>-1.041084</td>\n",
              "      <td>-1.249427</td>\n",
              "      <td>-0.969554</td>\n",
              "      <td>-1.286876</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201595</th>\n",
              "      <td>0.539989</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.577538</td>\n",
              "      <td>-0.199466</td>\n",
              "      <td>-0.817476</td>\n",
              "      <td>-0.964401</td>\n",
              "      <td>-0.725919</td>\n",
              "      <td>-0.665963</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239570</th>\n",
              "      <td>0.965488</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>-0.047646</td>\n",
              "      <td>-0.180216</td>\n",
              "      <td>0.158003</td>\n",
              "      <td>-0.226468</td>\n",
              "      <td>1.832942</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201092</th>\n",
              "      <td>0.534278</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.192084</td>\n",
              "      <td>0.237017</td>\n",
              "      <td>-0.012185</td>\n",
              "      <td>0.231588</td>\n",
              "      <td>-0.177741</td>\n",
              "      <td>1.832942</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127269</th>\n",
              "      <td>-0.297592</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>0.616567</td>\n",
              "      <td>1.399150</td>\n",
              "      <td>0.979548</td>\n",
              "      <td>0.796798</td>\n",
              "      <td>1.078997</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169794</th>\n",
              "      <td>0.181014</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>-0.237421</td>\n",
              "      <td>-0.929280</td>\n",
              "      <td>-0.766312</td>\n",
              "      <td>-0.847737</td>\n",
              "      <td>1.078997</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103995</th>\n",
              "      <td>-0.559291</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.577538</td>\n",
              "      <td>-0.180488</td>\n",
              "      <td>-0.855489</td>\n",
              "      <td>-0.473213</td>\n",
              "      <td>-0.847737</td>\n",
              "      <td>-0.307717</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133077</th>\n",
              "      <td>-0.231934</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.577538</td>\n",
              "      <td>-0.294354</td>\n",
              "      <td>-0.855489</td>\n",
              "      <td>-0.687138</td>\n",
              "      <td>-0.847737</td>\n",
              "      <td>-0.925448</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227305</th>\n",
              "      <td>0.827974</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.807273</td>\n",
              "      <td>-0.142533</td>\n",
              "      <td>-0.193163</td>\n",
              "      <td>-0.491532</td>\n",
              "      <td>-0.238650</td>\n",
              "      <td>-0.307717</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101555</th>\n",
              "      <td>-0.586327</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.192084</td>\n",
              "      <td>0.616567</td>\n",
              "      <td>-0.224926</td>\n",
              "      <td>-0.173595</td>\n",
              "      <td>-0.226468</td>\n",
              "      <td>0.270539</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows  302 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffff4fd3-9835-449d-ac87-12ceb9109b42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffff4fd3-9835-449d-ac87-12ceb9109b42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffff4fd3-9835-449d-ac87-12ceb9109b42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(dataset_class=data)\n"
      ],
      "metadata": {
        "id": "xvXLiCAdNlMY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params = {\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.01,\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'scale_pos_weight': 15,\n",
        "    'subsample':0.6,\n",
        "    'colsample_bytree':0.5\n",
        "}\n",
        "model.train_model(xgb_params)\n"
      ],
      "metadata": {
        "id": "6s1LcWHQgBI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_model()"
      ],
      "metadata": {
        "id": "pSnjl7C_JRXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OS-15Y0qF3j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function for Bayesian optimization\n",
        "def xgb_objective(n_estimators, gamma, scale_pos_weight,colsample_bynode,\n",
        "                  learning_rate, max_depth, subsample, colsample_bytree):\n",
        "    # Convert hyperparameters to appropriate types\n",
        "    learning_rate = float(learning_rate)\n",
        "    max_depth = int(max_depth)\n",
        "    subsample = max(min(float(subsample), 1), 0)\n",
        "    colsample_bytree = max(min(float(colsample_bytree), 1), 0)\n",
        "    colsample_bynode = max(min(float(colsample_bytree), 1), 0)\n",
        "\n",
        "\n",
        "\n",
        "    # Create the XGBClassifier model with the specified hyperparameters\n",
        "    model = xgb.XGBClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        gamma = gamma,\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        colsample_bynode=colsample_bynode,\n",
        "        learning_rate=learning_rate,\n",
        "        max_depth=max_depth,\n",
        "        subsample=subsample,\n",
        "        colsample_bytree=colsample_bytree,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Perform cross-validation and calculate the ROC AUC score\n",
        "    roc_auc = cross_val_score(model, X, y, cv=5, scoring='roc_auc').mean()\n",
        "\n",
        "    # Return the negative ROC AUC score (Bayesian optimization minimizes the objective function)\n",
        "    return -roc_auc\n",
        "\n",
        "# Define the parameter ranges for Bayesian optimization\n",
        "pbounds = {\n",
        "    'n_estimators':(100, 1250),\n",
        "    'gamma':(0.2, 1),\n",
        "    'scale_pos_weight':(1,50),\n",
        "    'colsample_bynode' : (0.3,1),\n",
        "    'learning_rate': (0.001, 0.1),\n",
        "    'max_depth': (3, 14),\n",
        "    'subsample': (0.25, 1),\n",
        "    'colsample_bytree': (0.25, 1)\n",
        "}\n",
        "\n",
        "# Perform Bayesian optimization\n",
        "optimizer = BayesianOptimization(\n",
        "    f=xgb_objective,\n",
        "    pbounds=pbounds,\n",
        "    random_state=42,\n",
        "    verbose=2\n",
        ")\n",
        "optimizer.maximize(init_points=10, n_iter=30)\n",
        "\n",
        "# Get the best hyperparameters and maximum ROC AUC score\n",
        "best_params = optimizer.max['params']\n",
        "best_score = -optimizer.max['target']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U9ps3yuxDXEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "a7df9376-8034-47e7-cb58-60207e7c85c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   iter    |  target   | colsam... | colsam... |   gamma   | learni... | max_depth | n_esti... | scale_... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4a816a550435>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m )\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Get the best hyperparameters and maximum ROC AUC score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-4a816a550435>\u001b[0m in \u001b[0;36mxgb_objective\u001b[0;34m(n_estimators, gamma, scale_pos_weight, colsample_bynode, learning_rate, max_depth, subsample, colsample_bytree)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Perform cross-validation and calculate the ROC AUC score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Return the negative ROC AUC score (Bayesian optimization minimizes the objective function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    283\u001b[0m     )\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1490, in fit\n    self._Booster = train(\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 182, in train\n    for i in range(start_iteration, num_boost_round):\nTypeError: 'numpy.float64' object cannot be interpreted as an integer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the final XGBClassifier model with the best hyperparameters\n",
        "best_model = xgb.XGBClassifier(\n",
        "    \n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    max_depth=int(best_params['max_depth']),\n",
        "    subsample=best_params['subsample'],\n",
        "    colsample_bytree=best_params['colsample_bytree'],\n",
        "    random_state=42\n",
        ")\n",
        "best_model.fit(X, y)"
      ],
      "metadata": {
        "id": "E2lGUvC_EZb3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}